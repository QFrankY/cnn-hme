{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drTZIgeuA4S7",
        "colab_type": "text"
      },
      "source": [
        "#Fashion Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LymKH3tAeIN9",
        "colab_type": "code",
        "outputId": "4e796df6-bbed-463d-db33-6de61f2107ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJZaZD00Kkfe",
        "colab_type": "text"
      },
      "source": [
        "### Acquiring Fashion Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWCSC8y0KlM2",
        "colab_type": "code",
        "outputId": "694d568b-4cb1-491a-e298-ca57b04b7d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "### Acquiring Kimia Lab Histopathology Image Dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "time: 3.92 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCJbyKXHnFXM",
        "colab_type": "code",
        "outputId": "deee8672-462b-486c-9f6a-b5ad05cdd128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "# Checking distribution of labels\n",
        "Label_map = {}\n",
        "for i, y in enumerate(y_train):\n",
        "  if y in Label_map:\n",
        "    Label_map[y].append(i)\n",
        "  else:\n",
        "    Label_map[y] = [i]\n",
        "\n",
        "# View 12 random images with specific label\n",
        "rows = 2\n",
        "columns = 5\n",
        "scale_factor = 15\n",
        "\n",
        "def ShowImages():\n",
        "  # Doesn't actually shuffle the training set\n",
        "  figsize_x = x_train[0].shape[1] * columns / scale_factor\n",
        "  figsize_y = x_train[0].shape[0] * rows / scale_factor\n",
        "  fig = plt.figure(figsize=(figsize_x, figsize_y))\n",
        "  for i in range(1, columns*rows +1):\n",
        "    np.random.shuffle(Label_map[i - 1])\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    img_index = Label_map[i - 1][0]\n",
        "    plt.imshow(x_train[img_index], cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "ShowImages()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAADrCAYAAABO8B3xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 672x268.8 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 970 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfrF-ec-oFFo",
        "colab_type": "code",
        "outputId": "d11bcce4-988a-4870-b231-3be6c0b1d283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "for i in range(0, 10):\n",
        "  print(len(Label_map.get(i)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "6000\n",
            "time: 2.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiRWy9_VuchV",
        "colab_type": "code",
        "outputId": "c8de9245-4068-4811-f1c3-fa7222117c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def convertOneHot(labels, num_classes):\n",
        "  return np.array([np.eye(num_classes)[label] for label in labels])\n",
        "\n",
        "# Normalize images and add channel axis\n",
        "X_train = (x_train/255)[..., np.newaxis] \n",
        "X_test = (x_test/255)[..., np.newaxis] \n",
        "\n",
        "# Convert labels to one hot\n",
        "num_classes = max(y_train) + 1\n",
        "Classes = np.unique(y_train)\n",
        "Y_train = convertOneHot(y_train, num_classes)\n",
        "Y_test = convertOneHot(y_test, num_classes)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "time: 617 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFrUrwJlQbgs",
        "colab_type": "text"
      },
      "source": [
        "# Single Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXNtxFP4LLFp",
        "colab_type": "code",
        "outputId": "67f47bf5-28ea-401c-aa05-5dc185f24f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def build_and_train(x_train, y_train, model=None, epochs=25):\n",
        "  # Randomly break off data for validation\n",
        "  x_t, x_v, y_t, y_v = train_test_split(x_train, y_train)\n",
        "  \n",
        "  # Performing image augmentations\n",
        "  # Augment test images\n",
        "  train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "      horizontal_flip=True,\n",
        "  )\n",
        "\n",
        "  if model == None:\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=x_train[0].shape),\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\n",
        "        keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.BatchNormalization(momentum=0.1),\n",
        "        keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(rate=0.25),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(y_train[0].shape[0]),\n",
        "    ]);\n",
        "  \n",
        "  # Training model\n",
        "  Best_model = 'best_model.h5'\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer()\n",
        "  model.compile(optimizer=optimizer, loss=tf.losses.softmax_cross_entropy, metrics=['accuracy'])\n",
        "\n",
        "  # Set callback functions to early stop training and save the best model so far\n",
        "  callbacks = [keras.callbacks.ModelCheckpoint(filepath=Best_model, monitor='val_acc', save_best_only=True)]\n",
        "  \n",
        "  model.fit_generator(\n",
        "    train_datagen.flow(x_t, y_t, batch_size=32),\n",
        "    steps_per_epoch=len(x_t) / 16,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_v, y_v),\n",
        "    callbacks=callbacks,\n",
        "  )\n",
        "  \n",
        "  best = keras.models.load_model(Best_model)\n",
        "  best.compile(optimizer=optimizer, loss=tf.losses.softmax_cross_entropy, metrics=['accuracy'])\n",
        "  return best"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 27.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHjau4jgsnhT",
        "colab_type": "code",
        "outputId": "23bf1f45-ea5e-4bc2-8fa6-85573984a422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1729
        }
      },
      "source": [
        "best = build_and_train(X_train, Y_train)\n",
        "\n",
        "# Evaluate models\n",
        "results = best.evaluate(X_test, Y_test)\n",
        "print(best.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "15000/15000 [==============================] - 2s 152us/sample - loss: 0.3801 - acc: 0.8612\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5515 - acc: 0.7992 - val_loss: 0.3800 - val_acc: 0.8612\n",
            "Epoch 2/25\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 0.3608 - acc: 0.8679\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.3714 - acc: 0.8660 - val_loss: 0.3608 - val_acc: 0.8679\n",
            "Epoch 3/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.3253 - acc: 0.8821\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.3255 - acc: 0.8829 - val_loss: 0.3253 - val_acc: 0.8821\n",
            "Epoch 4/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2966 - acc: 0.8917\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.2981 - acc: 0.8935 - val_loss: 0.2965 - val_acc: 0.8917\n",
            "Epoch 5/25\n",
            "15000/15000 [==============================] - 2s 154us/sample - loss: 0.3021 - acc: 0.8921\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.2756 - acc: 0.9007 - val_loss: 0.3020 - val_acc: 0.8921\n",
            "Epoch 6/25\n",
            "15000/15000 [==============================] - 2s 142us/sample - loss: 0.2862 - acc: 0.8953\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.2600 - acc: 0.9057 - val_loss: 0.2862 - val_acc: 0.8953\n",
            "Epoch 7/25\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 0.2693 - acc: 0.9015\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.2453 - acc: 0.9112 - val_loss: 0.2692 - val_acc: 0.9015\n",
            "Epoch 8/25\n",
            "15000/15000 [==============================] - 2s 136us/sample - loss: 0.2630 - acc: 0.9066\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.2385 - acc: 0.9144 - val_loss: 0.2630 - val_acc: 0.9066\n",
            "Epoch 9/25\n",
            "15000/15000 [==============================] - 2s 132us/sample - loss: 0.2550 - acc: 0.9079\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.2260 - acc: 0.9180 - val_loss: 0.2549 - val_acc: 0.9079\n",
            "Epoch 10/25\n",
            "15000/15000 [==============================] - 2s 130us/sample - loss: 0.2786 - acc: 0.9045\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.2137 - acc: 0.9224 - val_loss: 0.2785 - val_acc: 0.9045\n",
            "Epoch 11/25\n",
            "15000/15000 [==============================] - 2s 140us/sample - loss: 0.2565 - acc: 0.9089\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.2037 - acc: 0.9250 - val_loss: 0.2564 - val_acc: 0.9089\n",
            "Epoch 12/25\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.2724 - acc: 0.9066\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1974 - acc: 0.9287 - val_loss: 0.2723 - val_acc: 0.9066\n",
            "Epoch 13/25\n",
            "15000/15000 [==============================] - 2s 131us/sample - loss: 0.2586 - acc: 0.9103\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.1880 - acc: 0.9310 - val_loss: 0.2586 - val_acc: 0.9103\n",
            "Epoch 14/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2604 - acc: 0.9096\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.1829 - acc: 0.9333 - val_loss: 0.2603 - val_acc: 0.9096\n",
            "Epoch 15/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2547 - acc: 0.9107\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.1747 - acc: 0.9364 - val_loss: 0.2546 - val_acc: 0.9107\n",
            "Epoch 16/25\n",
            "15000/15000 [==============================] - 2s 136us/sample - loss: 0.2669 - acc: 0.9107\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.1703 - acc: 0.9378 - val_loss: 0.2668 - val_acc: 0.9107\n",
            "Epoch 17/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2604 - acc: 0.9108\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.1674 - acc: 0.9380 - val_loss: 0.2604 - val_acc: 0.9108\n",
            "Epoch 18/25\n",
            "15000/15000 [==============================] - 2s 153us/sample - loss: 0.2750 - acc: 0.9065\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1575 - acc: 0.9420 - val_loss: 0.2750 - val_acc: 0.9065\n",
            "Epoch 19/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2596 - acc: 0.9157\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1532 - acc: 0.9434 - val_loss: 0.2596 - val_acc: 0.9157\n",
            "Epoch 20/25\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.2726 - acc: 0.9127\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.1474 - acc: 0.9458 - val_loss: 0.2726 - val_acc: 0.9127\n",
            "Epoch 21/25\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 0.2765 - acc: 0.9117\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.1423 - acc: 0.9472 - val_loss: 0.2765 - val_acc: 0.9117\n",
            "Epoch 22/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.2750 - acc: 0.9129\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 0.1372 - acc: 0.9495 - val_loss: 0.2750 - val_acc: 0.9129\n",
            "Epoch 23/25\n",
            "15000/15000 [==============================] - 2s 135us/sample - loss: 0.2745 - acc: 0.9125\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 0.1364 - acc: 0.9496 - val_loss: 0.2744 - val_acc: 0.9125\n",
            "Epoch 24/25\n",
            "15000/15000 [==============================] - 2s 133us/sample - loss: 0.2871 - acc: 0.9135\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.1291 - acc: 0.9525 - val_loss: 0.2871 - val_acc: 0.9135\n",
            "Epoch 25/25\n",
            "15000/15000 [==============================] - 2s 134us/sample - loss: 0.3122 - acc: 0.9153\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1239 - acc: 0.9543 - val_loss: 0.3124 - val_acc: 0.9153\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "10000/10000 [==============================] - 1s 126us/sample - loss: 0.3076 - acc: 0.9051\n",
            "['loss', 'acc']\n",
            "[0.3075728793114424, 0.9051]\n",
            "time: 5min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "074s5bxEtHpp",
        "colab_type": "code",
        "outputId": "3ee1a376-8660-439d-ce36-2a5a1885f865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "  \n",
        "Y_pred = best.predict(X_test, batch_size=1)\n",
        "plot_confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1), Classes)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[847   3  31  15   5   1  92   0   6   0]\n",
            " [  0 972   2  17   2   0   5   0   2   0]\n",
            " [ 11   0 883   6  51   0  47   0   2   0]\n",
            " [ 10   2  25 901  28   0  29   0   4   1]\n",
            " [  0   0  45  24 885   0  44   0   2   0]\n",
            " [  0   0   0   1   0 955   0  26   0  18]\n",
            " [ 95   1  88  15  92   0 700   0   9   0]\n",
            " [  0   0   0   0   0   5   0 975   0  20]\n",
            " [  2   0   2   4   7   4   4   1 975   1]\n",
            " [  0   0   0   0   0   6   0  36   0 958]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEYCAYAAADBOEomAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 19.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zfK3m6Xy6KU",
        "colab_type": "text"
      },
      "source": [
        "# Classifier Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OEWlfBecEWO",
        "colab_type": "code",
        "outputId": "888b0c87-bfc3-4a84-c38f-338e42db7431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def buildClassDict(class_groups):\n",
        "  class_dict = {}\n",
        "  for i, group in enumerate(class_groups):\n",
        "    for val in group:\n",
        "      class_dict[val] = i\n",
        "  return class_dict\n",
        "\n",
        "def remapAndFilter(data, labels, class_dict, class_groups):\n",
        "  new_labels = []\n",
        "  new_data = []\n",
        "  for idx, label in enumerate(labels):\n",
        "    if label in class_dict:\n",
        "      new_label = class_dict[label]\n",
        "      new_labels.append(new_label)\n",
        "      new_data.append(data[idx])\n",
        "  \n",
        "  return np.array(new_data), convertOneHot(new_labels, len(class_groups))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.04 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cdc818e7-b726-4591-c8aa-8f5d01ed2f75",
        "id": "EY7pixXZIaBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1639
        }
      },
      "source": [
        "Class_groups = [[0, 1, 2, 3, 4, 6], [5, 7, 9], [8]]\n",
        "Class_dict = buildClassDict(Class_groups)\n",
        "\n",
        "remapped_x_train, remapped_y_train = remapAndFilter(X_train, y_train, Class_dict, Class_groups)\n",
        "remapped_x_test, remapped_y_test = remapAndFilter(X_test, y_test, Class_dict, Class_groups)\n",
        "\n",
        "root = build_and_train(remapped_x_train, remapped_y_train)\n",
        "\n",
        "# Evaluate model\n",
        "results = root.evaluate(remapped_x_test, remapped_y_test)\n",
        "print(root.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "15000/15000 [==============================] - 3s 175us/sample - loss: 0.0605 - acc: 0.9857\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.0530 - acc: 0.9849 - val_loss: 0.0605 - val_acc: 0.9857\n",
            "Epoch 2/25\n",
            "15000/15000 [==============================] - 2s 146us/sample - loss: 0.0370 - acc: 0.9904\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0290 - acc: 0.9922 - val_loss: 0.0370 - val_acc: 0.9904\n",
            "Epoch 3/25\n",
            "15000/15000 [==============================] - 2s 160us/sample - loss: 0.0263 - acc: 0.9926\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0222 - acc: 0.9938 - val_loss: 0.0263 - val_acc: 0.9926\n",
            "Epoch 4/25\n",
            "15000/15000 [==============================] - 2s 146us/sample - loss: 0.0425 - acc: 0.9905\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0189 - acc: 0.9945 - val_loss: 0.0424 - val_acc: 0.9905\n",
            "Epoch 5/25\n",
            "15000/15000 [==============================] - 2s 146us/sample - loss: 0.0183 - acc: 0.9939\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0174 - acc: 0.9956 - val_loss: 0.0183 - val_acc: 0.9939\n",
            "Epoch 6/25\n",
            "15000/15000 [==============================] - 2s 146us/sample - loss: 0.0202 - acc: 0.9934\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.0202 - val_acc: 0.9934\n",
            "Epoch 7/25\n",
            "15000/15000 [==============================] - 2s 151us/sample - loss: 0.0239 - acc: 0.9937\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0141 - acc: 0.9960 - val_loss: 0.0239 - val_acc: 0.9937\n",
            "Epoch 8/25\n",
            "15000/15000 [==============================] - 2s 149us/sample - loss: 0.0337 - acc: 0.9914\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.0337 - val_acc: 0.9914\n",
            "Epoch 9/25\n",
            "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0190 - acc: 0.9940\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0121 - acc: 0.9966 - val_loss: 0.0190 - val_acc: 0.9940\n",
            "Epoch 10/25\n",
            "15000/15000 [==============================] - 2s 147us/sample - loss: 0.0215 - acc: 0.9945\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0109 - acc: 0.9968 - val_loss: 0.0215 - val_acc: 0.9945\n",
            "Epoch 11/25\n",
            "15000/15000 [==============================] - 2s 163us/sample - loss: 0.0281 - acc: 0.9938\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0281 - val_acc: 0.9938\n",
            "Epoch 12/25\n",
            "15000/15000 [==============================] - 2s 146us/sample - loss: 0.0235 - acc: 0.9941\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0235 - val_acc: 0.9941\n",
            "Epoch 13/25\n",
            "15000/15000 [==============================] - 2s 148us/sample - loss: 0.0173 - acc: 0.9954\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0173 - val_acc: 0.9954\n",
            "Epoch 14/25\n",
            "15000/15000 [==============================] - 2s 148us/sample - loss: 0.0300 - acc: 0.9949\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0299 - val_acc: 0.9949\n",
            "Epoch 15/25\n",
            "15000/15000 [==============================] - 3s 168us/sample - loss: 0.0229 - acc: 0.9956\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0229 - val_acc: 0.9956\n",
            "Epoch 16/25\n",
            "15000/15000 [==============================] - 2s 147us/sample - loss: 0.0214 - acc: 0.9951\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0214 - val_acc: 0.9951\n",
            "Epoch 17/25\n",
            "15000/15000 [==============================] - 2s 150us/sample - loss: 0.0194 - acc: 0.9955\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 0.0194 - val_acc: 0.9955\n",
            "Epoch 18/25\n",
            "15000/15000 [==============================] - 2s 145us/sample - loss: 0.0284 - acc: 0.9923\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0284 - val_acc: 0.9923\n",
            "Epoch 19/25\n",
            "15000/15000 [==============================] - 2s 147us/sample - loss: 0.0267 - acc: 0.9953\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0267 - val_acc: 0.9953\n",
            "Epoch 20/25\n",
            "15000/15000 [==============================] - 2s 144us/sample - loss: 0.0236 - acc: 0.9947\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0236 - val_acc: 0.9947\n",
            "Epoch 21/25\n",
            "15000/15000 [==============================] - 3s 167us/sample - loss: 0.0237 - acc: 0.9953\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0236 - val_acc: 0.9953\n",
            "Epoch 22/25\n",
            "15000/15000 [==============================] - 2s 146us/sample - loss: 0.0220 - acc: 0.9950\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0220 - val_acc: 0.9950\n",
            "Epoch 23/25\n",
            "15000/15000 [==============================] - 2s 148us/sample - loss: 0.0242 - acc: 0.9955\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0242 - val_acc: 0.9955\n",
            "Epoch 24/25\n",
            "15000/15000 [==============================] - 2s 148us/sample - loss: 0.0216 - acc: 0.9957\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0216 - val_acc: 0.9957\n",
            "Epoch 25/25\n",
            "15000/15000 [==============================] - 2s 148us/sample - loss: 0.0221 - acc: 0.9956\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0221 - val_acc: 0.9956\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "10000/10000 [==============================] - 2s 151us/sample - loss: 0.0266 - acc: 0.9960\n",
            "['loss', 'acc']\n",
            "[0.026645247231987662, 0.996]\n",
            "time: 5min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeLeecPPG6e2",
        "colab_type": "code",
        "outputId": "bd389497-95ea-49a4-da13-991e449fe51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1657
        }
      },
      "source": [
        "Cloth_groups = [[x] for x in Class_groups[0]]\n",
        "Cloth_dict = buildClassDict(Cloth_groups)\n",
        "\n",
        "remapped_x_train, remapped_y_train = remapAndFilter(X_train, y_train, Cloth_dict, Cloth_groups)\n",
        "remapped_x_test, remapped_y_test = remapAndFilter(X_test, y_test, Cloth_dict, Cloth_groups)\n",
        "\n",
        "cloth = build_and_train(remapped_x_train, remapped_y_train)\n",
        "\n",
        "# Evaluate model\n",
        "results = cloth.evaluate(remapped_x_test, remapped_y_test)\n",
        "print(cloth.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "9000/9000 [==============================] - 2s 210us/sample - loss: 0.5090 - acc: 0.8073\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 12s 14ms/step - loss: 0.6371 - acc: 0.7559 - val_loss: 0.5094 - val_acc: 0.8073\n",
            "Epoch 2/25\n",
            "9000/9000 [==============================] - 1s 143us/sample - loss: 0.4409 - acc: 0.8327\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.4593 - acc: 0.8268 - val_loss: 0.4422 - val_acc: 0.8327\n",
            "Epoch 3/25\n",
            "9000/9000 [==============================] - 1s 143us/sample - loss: 0.3965 - acc: 0.8518\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.4075 - acc: 0.8477 - val_loss: 0.3963 - val_acc: 0.8518\n",
            "Epoch 4/25\n",
            "9000/9000 [==============================] - 1s 144us/sample - loss: 0.3835 - acc: 0.8568\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.3740 - acc: 0.8594 - val_loss: 0.3831 - val_acc: 0.8568\n",
            "Epoch 5/25\n",
            "9000/9000 [==============================] - 1s 144us/sample - loss: 0.3856 - acc: 0.8560\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.3457 - acc: 0.8723 - val_loss: 0.3852 - val_acc: 0.8560\n",
            "Epoch 6/25\n",
            "9000/9000 [==============================] - 1s 143us/sample - loss: 0.3816 - acc: 0.8572\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.3282 - acc: 0.8783 - val_loss: 0.3812 - val_acc: 0.8572\n",
            "Epoch 7/25\n",
            "9000/9000 [==============================] - 1s 144us/sample - loss: 0.3552 - acc: 0.8688\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.3072 - acc: 0.8854 - val_loss: 0.3549 - val_acc: 0.8688\n",
            "Epoch 8/25\n",
            "9000/9000 [==============================] - 1s 145us/sample - loss: 0.3481 - acc: 0.8739\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.2891 - acc: 0.8934 - val_loss: 0.3478 - val_acc: 0.8739\n",
            "Epoch 9/25\n",
            "9000/9000 [==============================] - 1s 143us/sample - loss: 0.3498 - acc: 0.8717\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.2780 - acc: 0.8957 - val_loss: 0.3496 - val_acc: 0.8717\n",
            "Epoch 10/25\n",
            "9000/9000 [==============================] - 1s 141us/sample - loss: 0.3693 - acc: 0.8720\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.2559 - acc: 0.9040 - val_loss: 0.3693 - val_acc: 0.8720\n",
            "Epoch 11/25\n",
            "9000/9000 [==============================] - 1s 150us/sample - loss: 0.3600 - acc: 0.8737\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.2448 - acc: 0.9082 - val_loss: 0.3596 - val_acc: 0.8737\n",
            "Epoch 12/25\n",
            "9000/9000 [==============================] - 1s 163us/sample - loss: 0.3774 - acc: 0.8752\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 9s 10ms/step - loss: 0.2355 - acc: 0.9118 - val_loss: 0.3767 - val_acc: 0.8752\n",
            "Epoch 13/25\n",
            "9000/9000 [==============================] - 1s 147us/sample - loss: 0.3831 - acc: 0.8770\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.2247 - acc: 0.9167 - val_loss: 0.3827 - val_acc: 0.8770\n",
            "Epoch 14/25\n",
            "9000/9000 [==============================] - 1s 164us/sample - loss: 0.3960 - acc: 0.8692\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.2079 - acc: 0.9218 - val_loss: 0.3951 - val_acc: 0.8692\n",
            "Epoch 15/25\n",
            "9000/9000 [==============================] - 1s 144us/sample - loss: 0.4312 - acc: 0.8658\n",
            "844/844 [==============================] - 9s 10ms/step - loss: 0.1990 - acc: 0.9250 - val_loss: 0.4309 - val_acc: 0.8658\n",
            "Epoch 16/25\n",
            "9000/9000 [==============================] - 1s 141us/sample - loss: 0.4118 - acc: 0.8696\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1984 - acc: 0.9251 - val_loss: 0.4113 - val_acc: 0.8696\n",
            "Epoch 17/25\n",
            "9000/9000 [==============================] - 1s 144us/sample - loss: 0.3870 - acc: 0.8809\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1887 - acc: 0.9296 - val_loss: 0.3864 - val_acc: 0.8809\n",
            "Epoch 18/25\n",
            "9000/9000 [==============================] - 1s 140us/sample - loss: 0.3972 - acc: 0.8763\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1750 - acc: 0.9335 - val_loss: 0.3964 - val_acc: 0.8763\n",
            "Epoch 19/25\n",
            "9000/9000 [==============================] - 1s 140us/sample - loss: 0.4269 - acc: 0.8741\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1654 - acc: 0.9367 - val_loss: 0.4262 - val_acc: 0.8741\n",
            "Epoch 20/25\n",
            "9000/9000 [==============================] - 1s 139us/sample - loss: 0.4410 - acc: 0.8718\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1632 - acc: 0.9380 - val_loss: 0.4400 - val_acc: 0.8718\n",
            "Epoch 21/25\n",
            "9000/9000 [==============================] - 1s 144us/sample - loss: 0.4499 - acc: 0.8687\n",
            "844/844 [==============================] - 7s 9ms/step - loss: 0.1521 - acc: 0.9430 - val_loss: 0.4492 - val_acc: 0.8687\n",
            "Epoch 22/25\n",
            "9000/9000 [==============================] - 1s 164us/sample - loss: 0.4684 - acc: 0.8763\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.1450 - acc: 0.9446 - val_loss: 0.4672 - val_acc: 0.8763\n",
            "Epoch 23/25\n",
            "9000/9000 [==============================] - 1s 145us/sample - loss: 0.4434 - acc: 0.8779\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1409 - acc: 0.9487 - val_loss: 0.4425 - val_acc: 0.8779\n",
            "Epoch 24/25\n",
            "9000/9000 [==============================] - 1s 164us/sample - loss: 0.4712 - acc: 0.8718\n",
            "844/844 [==============================] - 8s 10ms/step - loss: 0.1375 - acc: 0.9498 - val_loss: 0.4704 - val_acc: 0.8718\n",
            "Epoch 25/25\n",
            "9000/9000 [==============================] - 1s 141us/sample - loss: 0.4714 - acc: 0.8743\n",
            "844/844 [==============================] - 8s 9ms/step - loss: 0.1358 - acc: 0.9513 - val_loss: 0.4703 - val_acc: 0.8743\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "6000/6000 [==============================] - 1s 187us/sample - loss: 0.4039 - acc: 0.8733\n",
            "['loss', 'acc']\n",
            "[0.40392655112346015, 0.87333333]\n",
            "time: 3min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEecvgWCLm-l",
        "colab_type": "code",
        "outputId": "aedac943-9f97-4270-e2d5-6eaf01df79c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1621
        }
      },
      "source": [
        "Shoes_groups = [[5], [7], [9]]\n",
        "Shoes_dict = buildClassDict(Shoes_groups)\n",
        "\n",
        "remapped_x_train, remapped_y_train = remapAndFilter(X_train, y_train, Shoes_dict, Shoes_groups)\n",
        "remapped_x_test, remapped_y_test = remapAndFilter(X_test, y_test, Shoes_dict, Shoes_groups)\n",
        "\n",
        "shoes = build_and_train(remapped_x_train, remapped_y_train)\n",
        "\n",
        "# Evaluate model\n",
        "results = shoes.evaluate(remapped_x_test, remapped_y_test)\n",
        "print(shoes.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "4500/4500 [==============================] - 1s 257us/sample - loss: 0.1742 - acc: 0.9369\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 8s 20ms/step - loss: 0.2610 - acc: 0.9030 - val_loss: 0.1739 - val_acc: 0.9369\n",
            "Epoch 2/25\n",
            "4500/4500 [==============================] - 1s 150us/sample - loss: 0.1459 - acc: 0.9533\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.1632 - acc: 0.9416 - val_loss: 0.1458 - val_acc: 0.9533\n",
            "Epoch 3/25\n",
            "4500/4500 [==============================] - 1s 152us/sample - loss: 0.1394 - acc: 0.9496\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.1298 - acc: 0.9544 - val_loss: 0.1395 - val_acc: 0.9496\n",
            "Epoch 4/25\n",
            "4500/4500 [==============================] - 1s 153us/sample - loss: 0.1189 - acc: 0.9598\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.1192 - acc: 0.9585 - val_loss: 0.1189 - val_acc: 0.9598\n",
            "Epoch 5/25\n",
            "4500/4500 [==============================] - 1s 157us/sample - loss: 0.1103 - acc: 0.9613\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.1005 - acc: 0.9633 - val_loss: 0.1103 - val_acc: 0.9613\n",
            "Epoch 6/25\n",
            "4500/4500 [==============================] - 1s 151us/sample - loss: 0.1141 - acc: 0.9589\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0961 - acc: 0.9654 - val_loss: 0.1143 - val_acc: 0.9589\n",
            "Epoch 7/25\n",
            "4500/4500 [==============================] - 1s 145us/sample - loss: 0.1051 - acc: 0.9642\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0909 - acc: 0.9676 - val_loss: 0.1049 - val_acc: 0.9642\n",
            "Epoch 8/25\n",
            "4500/4500 [==============================] - 1s 160us/sample - loss: 0.1024 - acc: 0.9629\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0834 - acc: 0.9713 - val_loss: 0.1025 - val_acc: 0.9629\n",
            "Epoch 9/25\n",
            "4500/4500 [==============================] - 1s 180us/sample - loss: 0.1213 - acc: 0.9653\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 5s 11ms/step - loss: 0.0755 - acc: 0.9734 - val_loss: 0.1215 - val_acc: 0.9653\n",
            "Epoch 10/25\n",
            "4500/4500 [==============================] - 1s 173us/sample - loss: 0.1129 - acc: 0.9624\n",
            "422/422 [==============================] - 5s 11ms/step - loss: 0.0756 - acc: 0.9730 - val_loss: 0.1128 - val_acc: 0.9624\n",
            "Epoch 11/25\n",
            "4500/4500 [==============================] - 1s 148us/sample - loss: 0.1027 - acc: 0.9627\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0670 - acc: 0.9766 - val_loss: 0.1026 - val_acc: 0.9627\n",
            "Epoch 12/25\n",
            "4500/4500 [==============================] - 1s 150us/sample - loss: 0.1493 - acc: 0.9582\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0627 - acc: 0.9774 - val_loss: 0.1491 - val_acc: 0.9582\n",
            "Epoch 13/25\n",
            "4500/4500 [==============================] - 1s 151us/sample - loss: 0.1191 - acc: 0.9613\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0602 - acc: 0.9787 - val_loss: 0.1190 - val_acc: 0.9613\n",
            "Epoch 14/25\n",
            "4500/4500 [==============================] - 1s 152us/sample - loss: 0.1035 - acc: 0.9667\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0607 - acc: 0.9782 - val_loss: 0.1034 - val_acc: 0.9667\n",
            "Epoch 15/25\n",
            "4500/4500 [==============================] - 1s 152us/sample - loss: 0.1413 - acc: 0.9600\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0561 - acc: 0.9806 - val_loss: 0.1413 - val_acc: 0.9600\n",
            "Epoch 16/25\n",
            "4500/4500 [==============================] - 1s 147us/sample - loss: 0.1434 - acc: 0.9604\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0475 - acc: 0.9827 - val_loss: 0.1437 - val_acc: 0.9604\n",
            "Epoch 17/25\n",
            "4500/4500 [==============================] - 1s 150us/sample - loss: 0.1201 - acc: 0.9649\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0502 - acc: 0.9827 - val_loss: 0.1199 - val_acc: 0.9649\n",
            "Epoch 18/25\n",
            "4500/4500 [==============================] - 1s 151us/sample - loss: 0.1145 - acc: 0.9633\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0478 - acc: 0.9824 - val_loss: 0.1143 - val_acc: 0.9633\n",
            "Epoch 19/25\n",
            "4500/4500 [==============================] - 1s 150us/sample - loss: 0.1209 - acc: 0.9616\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0472 - acc: 0.9825 - val_loss: 0.1212 - val_acc: 0.9616\n",
            "Epoch 20/25\n",
            "4500/4500 [==============================] - 1s 150us/sample - loss: 0.1208 - acc: 0.9653\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0418 - acc: 0.9844 - val_loss: 0.1205 - val_acc: 0.9653\n",
            "Epoch 21/25\n",
            "4500/4500 [==============================] - 1s 147us/sample - loss: 0.1195 - acc: 0.9656\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0417 - acc: 0.9857 - val_loss: 0.1192 - val_acc: 0.9656\n",
            "Epoch 22/25\n",
            "4500/4500 [==============================] - 1s 148us/sample - loss: 0.1208 - acc: 0.9691\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0367 - acc: 0.9877 - val_loss: 0.1205 - val_acc: 0.9691\n",
            "Epoch 23/25\n",
            "4500/4500 [==============================] - 1s 151us/sample - loss: 0.1291 - acc: 0.9662\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0371 - acc: 0.9866 - val_loss: 0.1291 - val_acc: 0.9662\n",
            "Epoch 24/25\n",
            "4500/4500 [==============================] - 1s 150us/sample - loss: 0.1355 - acc: 0.9671\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0356 - acc: 0.9873 - val_loss: 0.1352 - val_acc: 0.9671\n",
            "Epoch 25/25\n",
            "4500/4500 [==============================] - 1s 152us/sample - loss: 0.1378 - acc: 0.9633\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.0331 - acc: 0.9881 - val_loss: 0.1375 - val_acc: 0.9633\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "3000/3000 [==============================] - 1s 274us/sample - loss: 0.1059 - acc: 0.9697\n",
            "['loss', 'acc']\n",
            "[0.10585392540258666, 0.96966666]\n",
            "time: 1min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxyoXzBAMmWu",
        "colab_type": "text"
      },
      "source": [
        "### Combining Individual Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8wVAOirMhXz",
        "colab_type": "code",
        "outputId": "2f37b9af-efc5-47c2-b3dc-f5cf67b61f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.special import softmax\n",
        "\n",
        "def predict(x):\n",
        "  y_root = root.predict(x)\n",
        "  y_shoes = shoes.predict(x)\n",
        "  y_cloth = cloth.predict(x)\n",
        "  \n",
        "  y_pred = []\n",
        "  for (y_r, y_s, y_c) in zip(y_root, y_shoes, y_cloth):\n",
        "    # Normalize Predictions\n",
        "    y_r = softmax(y_r)\n",
        "    y_c = softmax(y_c)\n",
        "    y_s = softmax(y_s)\n",
        "    \n",
        "    y = np.zeros(num_classes)\n",
        "    y[8] = y_r[Class_dict[8]]\n",
        "    \n",
        "    for i in Class_groups[0]:\n",
        "      y[i] = y_r[0] * y_c[Cloth_dict[i]]\n",
        "      \n",
        "    for i in Class_groups[1]:\n",
        "      y[i] = y_r[1] * y_s[Shoes_dict[i]]\n",
        "       \n",
        "    y_pred.append(y)\n",
        " \n",
        "  return y_pred\n",
        "    \n",
        "y_pred = predict(X_test)\n",
        "y_labels = [np.argmax(pred) for pred in y_pred]\n",
        "\n",
        "accuracy_score(y_test, y_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.98 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy3yTqUrrpBi",
        "colab_type": "text"
      },
      "source": [
        "# Mixing Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F9TsHTarunX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root classifier\n",
        "Class_groups = [[0, 2, 3, 4, 6], [1], [5, 7, 9], [8]]\n",
        "Class_dict = buildClassDict(Class_groups)\n",
        "\n",
        "remapped_x_train, remapped_y_train = remapAndFilter(X_train, y_train, Class_dict, Class_groups)\n",
        "remapped_x_test, remapped_y_test = remapAndFilter(X_test, y_test, Class_dict, Class_groups)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=remapped_x_train[0].shape),\n",
        "    keras.layers.BatchNormalization(momentum=0.1),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(remapped_y_train[0].shape[0]),\n",
        "]);\n",
        "\n",
        "root = build_and_train(remapped_x_train, remapped_y_train, model, 5)\n",
        "\n",
        "# Evaluate model\n",
        "results = root.evaluate(remapped_x_test, remapped_y_test)\n",
        "print(root.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k22ygYN9uDo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cloth classifier\n",
        "Cloth_groups = [[0], [2], [3], [4], [6]]\n",
        "Cloth_dict = buildClassDict(Cloth_groups)\n",
        "\n",
        "remapped_x_train, remapped_y_train = remapAndFilter(X_train, y_train, Cloth_dict, Cloth_groups)\n",
        "remapped_x_test, remapped_y_test = remapAndFilter(X_test, y_test, Cloth_dict, Cloth_groups)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=remapped_x_train[0].shape),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(rate=0.25),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(remapped_y_train[0].shape[0]),\n",
        "]);\n",
        "\n",
        "cloth = build_and_train(remapped_x_train, remapped_y_train, model, 20)\n",
        "\n",
        "# Evaluate model\n",
        "results = cloth.evaluate(remapped_x_test, remapped_y_test)\n",
        "print(cloth.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZEKFkEY8WBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shoe classifier\n",
        "Shoes_groups = [[5], [7], [9]]\n",
        "Shoes_dict = buildClassDict(Shoes_groups)\n",
        "\n",
        "remapped_x_train, remapped_y_train = remapAndFilter(X_train, y_train, Shoes_dict, Shoes_groups)\n",
        "remapped_x_test, remapped_y_test = remapAndFilter(X_test, y_test, Shoes_dict, Shoes_groups)\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=remapped_x_train[0].shape),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(remapped_y_train[0].shape[0]),\n",
        "]);\n",
        "\n",
        "shoes = build_and_train(remapped_x_train, remapped_y_train, model, 10)\n",
        "\n",
        "# Evaluate model\n",
        "results = shoes.evaluate(remapped_x_test, remapped_y_test)\n",
        "print(shoes.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}